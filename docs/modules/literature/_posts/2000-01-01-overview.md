---
title: Overview
---

## Literature Research with AI: Overview

As I mentioned in our recent class discussion about Elicit and SciSpace, AI tools are increasingly transforming how we approach literature research. 
These platforms represent a significant shift from traditional keyword-based searches to more intelligent, semantic understanding of research questions.

## What Makes These Tools Different

**[Elicit](https://elicit.com)** and **[SciSpace](https://scispace.com)** (and many other tools) exemplify the new generation of AI research assistants that can process millions of academic papers and extract specific information based on natural language queries. 

Unlike general-purpose chatbots, these tools are specifically designed for academic research, 
drawing from extensive databases of peer-reviewed literature[^4][^5].

## The Citation Reliability Advantage

One of the most important distinctions between these specialized research tools and general AI chatbots is their approach to references. Research comparing AI tools found that **Elicit and SciSpace had negligible hallucination rates when it comes to citations** ([see here](https://www.nature.com/articles/s41598-023-41032-5)),
meaning the papers they reference are real and can be verified.  

When you use Elicit to search for papers on a specific research question, the tool searches across 125 million academic papers and provides actual citations you can follow up on. Similarly, SciSpace draws from over 200 million papers from databases like OpenAlex and Semantic Scholar.

:warning: Your usual PubMed search will scan a different set of papers, particularly when older sources are relevant.

## Text Generation Requires Careful Evaluation

While these tools won't make up fake citations, their **summarizations, extracted insights, and generated explanations should be treated with appropriate skepticism** (see [here](https://support.elicit.com/en/articles/549569)).
Studies indicate that Elicit-generated content is approximately 80-90% accurate, which means **one in every five to ten pieces of information could be incorrect**. 

The AI may miss important nuances, misinterpret study findings, or fail to capture the full context of research[^11][^12]. For instance, a tool might accurately identify a relevant paper but then provide a summary that oversimplifies the study's methodology or misrepresents its conclusions.

## A practical approach

As students beginning to work with these tools, I recommend this balanced approach:

1. **Trust the citations** - The papers these tools find are real and worth investigating
2. **Verify the content** - Always read the original sources for any claims that matter to your work
3. **Use AI summaries as starting points** - Treat generated text as a first draft that requires your critical evaluation
4. **Combine with traditional methods** - These tools work best when supplementing, not replacing, careful scholarly reading
 